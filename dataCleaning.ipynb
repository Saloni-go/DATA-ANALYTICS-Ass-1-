{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758ff9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spicy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95322414",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44866cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    try:\n",
    "        df=pd.read_csv(path)\n",
    "        print(f\"Dataset loaded successfully with shape: {df.shape}\")\n",
    "        return df \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf5c12",
   "metadata": {},
   "source": [
    "### REMOVING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4834298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df, col_name):\n",
    "    if col_name not in df.columns:\n",
    "        print(\"f: column 'col_name}' not found.\")\n",
    "        return \n",
    "    print(\"Checking column: {col_name}\")\n",
    "    col=df[col_name]\n",
    "\n",
    "    #traverse row by row\n",
    "    for i,val in enumerate(col):\n",
    "        if pd.isna(val):\n",
    "            print(f\"Row {i}: NULL/NaN value found.\")\n",
    "        elif isinstance(val,str) and val.strip()==\"\":  \n",
    "            print(f\"Row {i}: Empty string found.\")\n",
    "        elif isinstance(val,str) and val.lower() in [\"?\",\"na\",\"n/a\",\"none\"]:\n",
    "             print(f\"Row {i}: Invalid string '{val}' found.\")\n",
    "\n",
    "    print(\"Check complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6d4508",
   "metadata": {},
   "source": [
    "### CHECK FOR OUTLIERS\n",
    "If the data is unrealistic or very far away from avg and the rest of the values in the dataset. In that case, its necessary to once cross verify.\n",
    "\n",
    "1. IQR Method: If data is skewed on one side.\n",
    "eg. Income, Work hours, House prices, etc.\n",
    "\n",
    "2. Z-Score Method: If data is symmetric/Normal.\n",
    "eg. Height, Test Scores, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59dd64",
   "metadata": {},
   "source": [
    "#### IQR (Interquartile Range) Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de468e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers_iqr(df,column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Column '{column}' not found.\")\n",
    "        return\n",
    "\n",
    "    Q1=df[column].quantile(0.25) #value below which 25% of the data lies\n",
    "    Q3=df[column].quantile(0.75) #value above which 75% of the data lies\n",
    "    IQR=Q3-Q1  #Interquartile Range i.e. spread of the middle 50% of the data\n",
    "\n",
    "    lower_bound=Q1-1.5*IQR  #any value smaller than lower bound is too far below the normal range\n",
    "    upper_bound=Q3+1.5*IQR  #any value larger than upper bound is too far above the normal range\n",
    "    #1.5 is a factor commonly used as a standard rule of thumb (Tukey's method)\n",
    "\n",
    "    outliers=df[(df[column]<lower_bound) | (df[column]>upper_bound)]\n",
    "    if outliers.empty:\n",
    "        print(f\"No outliers found in column '{column}'.\")\n",
    "    else:\n",
    "        print(f\"Outliers found in column '{column}':\")\n",
    "        print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda421c",
   "metadata": {},
   "source": [
    "#### Z-Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e79026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_zscore_columnwise(df, threshold=3):\n",
    "    df_numeric = df.select_dtypes(include=[np.number])\n",
    "    outliers_dict = {}\n",
    "\n",
    "\n",
    "    for col in df_numeric.columns:\n",
    "        z_scores = np.abs(stats.zscore(df_numeric[col], nan_policy='omit'))\n",
    "        outliers = df_numeric[z_scores > threshold]\n",
    "        if not outliers.empty:\n",
    "            outliers_dict[col] = outliers\n",
    "            print(f\"Outliers found in column '{col}':\")\n",
    "            print(outliers)\n",
    "        else:\n",
    "            print(f\"No outliers found in column '{col}'.\")\n",
    "\n",
    "\n",
    "    return outliers_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c0591",
   "metadata": {},
   "source": [
    "### ENSURING CORRECT DATA TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23628828",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_data_type(df,col_name):\n",
    "    if col_name not in df.columns:\n",
    "        print(f\"Column '{col_name}' not found.\")\n",
    "        return df\n",
    "\n",
    "    # Check data type\n",
    "    if not pd.api.types.is_numeric_dtype(df[col_name]):\n",
    "        # Convert to numeric (coerce errors â†’ invalid parsing becomes NaN)\n",
    "        df[col_name] = pd.to_numeric(df[col_name], errors=\"coerce\")\n",
    "        print(f\"Converted column '{col_name}' to numeric.\")\n",
    "\n",
    "    # Confirm new type\n",
    "    print(df[col_name].dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba2327",
   "metadata": {},
   "source": [
    "#### REMOVE DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49db9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df, col_name):\n",
    "    if col_name not in df.columns:\n",
    "        print(f\"Column '{col_name}' not found.\")\n",
    "        return df\n",
    "        \n",
    "    before = df.shape[0]\n",
    "    df = df.drop_duplicates(subset=[col_name]).reset_index(drop=True)\n",
    "    after = df.shape[0]\n",
    "    print(f\"Duplicates removed based on column '{col_name}': {before - after}. New shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20e515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e1195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
